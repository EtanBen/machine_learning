import os.path
import numpy as np
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.datasets import load_digits

# TODO: Add necessary imports here
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.svm import SVC
from sklearn.base import BaseEstimator, TransformerMixin
from skimage.filters import sobel

class EdgeInfoPreprocessing(BaseEstimator, TransformerMixin):
    '''A class used to compute an average Sobel estimator on the image
       This class can be used in conjunction of other feature engineering
       using Pipelines or FeatureUnion
    '''
    def __init__(self):
        pass

    def fit(self, X, y=None):
        return self # No fitting needed for this processing

    def transform(self, X):
        sobel_feature = np.array([np.mean(sobel(img.reshape((8,8)))) for img in X]).reshape(-1, 1)
        return sobel_feature

# TODO: Fill out the useful code for this class


class ZonalInfoPreprocessing(BaseEstimator, TransformerMixin):
    '''A class used to compute zone information on the image
       This class can be used in conjunction of other feature engineering
       using Pipelines or FeatureUnion

       TODO: Continue this work
    '''

    def __init__(self):
        pass

    def fit(self, X, y=None):
        # No fitting needed
        return self

    def transform(self, X):
        features = []
        for image in X:
            img = image.reshape(8, 8)
            zone1 = np.mean(img[0:3, :])
            zone2 = np.mean(img[3:5, :])
            zone3 = np.mean(img[5:8, :])
            features.append([zone1, zone2, zone3])
        return np.array(features)


# The lines below shall not be modified!

# The following will be replaced by our own 
if os.path.isfile("test_data.npy"):
    X_test = np.load("test_data.npy")
    y_test = np.load("test_labels.npy")
    X_train, y_train = load_digits(return_X_y=True)
else:
    X, y = load_digits(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# TODO: Prepare your learning pipeline and set all the parameters for your final algorithm.

clf = Pipeline([('features', FeatureUnion([('zonal', ZonalInfoPreprocessing()),('edges', EdgeInfoPreprocessing()),('pca_pipeline', Pipeline([('scaler', StandardScaler()),  ('pca', PCA(n_components=28))]))])),  ('svc', SVC(kernel='rbf', C=10, gamma=0.01, random_state=42))  ])

# The next lines shall not be modified
clf.fit(X_train, y_train)
print(f"Score on the test set {clf.score(X_test, y_test)}")
